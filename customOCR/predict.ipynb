{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b0b8a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added to sys.path: c:\\code\\pororo_easyocr_main\n",
      "\n",
      "필요한 모듈을 모두 로드했습니다.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "# --- 로컬 Pororo 모듈 경로 설정 ---\n",
    "# 이 노트북 파일(predict.ipynb)은 customOCR 폴더에 있으므로,\n",
    "# pororo_main 폴더는 같은 레벨에 있다고 가정합니다.\n",
    "PORORO_PATH = os.path.abspath(os.path.join(os.path.dirname('.'), '..', 'pororo_easyocr_main'))\n",
    "if PORORO_PATH not in sys.path:\n",
    "    sys.path.append(PORORO_PATH)\n",
    "    print(f\"Added to sys.path: {PORORO_PATH}\")\n",
    "\n",
    "try:\n",
    "    from main import EasyPororoOcr, BaseOcr\n",
    "    import cv2\n",
    "    from abc import ABC, abstractmethod\n",
    "    from pororo import Pororo\n",
    "    from pororo.pororo import SUPPORTED_TASKS\n",
    "    from utils.image_util import plt_imshow, put_text\n",
    "    from utils.image_convert import convert_coord, crop\n",
    "    from utils.pre_processing import load_with_filter, roi_filter\n",
    "    from easyocr import Reader\n",
    "except ImportError:\n",
    "    print(f\"오류: '{PORORO_PATH}' 경로에서 Pororo 모듈을 찾을 수 없습니다.\")\n",
    "    print(\"customOCR 폴더와 같은 위치에 'pororo_main' 폴더가 있는지 확인해주세요.\")\n",
    "    # In a notebook, we might not want to exit, just raise the error.\n",
    "    raise\n",
    "\n",
    "from transformers import LayoutLMv3Processor, LayoutLMv3ForTokenClassification\n",
    "# config.py 파일이 src 폴더 안에 있으므로 경로를 추가해줍니다.\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname('.'), 'src')))\n",
    "from config import OUTPUT_DIR, id2label, DEVICE\n",
    "\n",
    "print(\"\\n필요한 모듈을 모두 로드했습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bc4abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DocumentPredictor 클래스가 'EasyPororoOcr' 엔진과 함께 업데이트되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DocumentPredictor:\n",
    "    \"\"\"\n",
    "    학습된 LayoutLMv3 모델을 사용하여 문서 정보를 추출하는 클래스.\n",
    "    (OCR 엔진을 EasyPororoOcr로 교체하여 정확도 향상)\n",
    "    \"\"\"\n",
    "    def __init__(self, model_path, confidence_threshold=0.85):\n",
    "        if not os.path.exists(model_path):\n",
    "            raise FileNotFoundError(f\"모델 경로를 찾을 수 없습니다: {model_path}. train.py를 먼저 실행하여 모델을 학습시키세요.\")\n",
    "        \n",
    "        print(\"모델과 프로세서를 로딩합니다...\")\n",
    "        self.processor = LayoutLMv3Processor.from_pretrained(model_path)\n",
    "        self.model = LayoutLMv3ForTokenClassification.from_pretrained(model_path)\n",
    "        self.model.to(DEVICE)\n",
    "        self.model.eval()\n",
    "        \n",
    "        # ★★★ 변경점 1: __init__에서 ocr_reader 초기화 코드 제거 ★★★\n",
    "        # self.ocr_reader = EasyPororoOcr(gpu=torch.cuda.is_available())\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "        print(f\"설정된 신뢰도 임계값: {self.confidence_threshold}\")\n",
    "\n",
    "    def _preprocess_image(self, image, top_crop_ratio=0.12, bottom_crop_ratio=0.08):\n",
    "        \"\"\"이미지의 상단/하단을 잘라내어 불필요한 UI 요소를 제거합니다.\"\"\"\n",
    "        width, height = image.size\n",
    "        top_crop = int(height * top_crop_ratio)\n",
    "        bottom_crop = int(height * (1 - bottom_crop_ratio))\n",
    "        \n",
    "        cropped_image = image.crop((0, top_crop, width, bottom_crop))\n",
    "        return cropped_image, top_crop\n",
    "\n",
    "    def _split_boxes_aggressively(self, ocr_words, ocr_boxes):\n",
    "        \"\"\"OCR 결과를 공백 기준으로 분할하되, 특정 패턴은 예외 처리합니다.\"\"\"\n",
    "        new_words, new_boxes = [], []\n",
    "        exception_pattern = re.compile(r'(\\d{1,2}월\\s\\d{1,2}일|\\d{1,4}\\.\\d{1,2}\\.\\d{1,2}|\\d{1,2}:\\d{1,2})')\n",
    "        for word, box in zip(ocr_words, ocr_boxes):\n",
    "            if exception_pattern.fullmatch(word):\n",
    "                new_words.append(word)\n",
    "                new_boxes.append(box)\n",
    "                continue\n",
    "            parts = word.split()\n",
    "            if len(parts) > 1:\n",
    "                new_words.extend(parts)\n",
    "                new_boxes.extend([box] * len(parts))\n",
    "            else:\n",
    "                new_words.append(word)\n",
    "                new_boxes.append(box)\n",
    "        return new_words, new_boxes\n",
    "\n",
    "    def predict(self, image_path):\n",
    "        \"\"\"단일 이미지에 대해 OCR 및 정보 추출을 수행합니다.\"\"\"\n",
    "        # ★★★ 변경점 2: predict 함수가 호출될 때마다 OCR 엔진을 새로 생성 ★★★\n",
    "        # 이렇게 하면 이미지마다 독립적인 OCR 상태를 유지하여 충돌을 방지합니다.\n",
    "        print(\"OCR 엔진(EasyPororoOcr)을 초기화합니다...\")\n",
    "        ocr_reader = EasyPororoOcr(gpu=torch.cuda.is_available())\n",
    "\n",
    "        print(f\"\\n'{os.path.basename(image_path)}'에서 텍스트를 추출합니다...\")\n",
    "        original_image = Image.open(image_path).convert(\"RGB\")\n",
    "        \n",
    "        cropped_image, y_offset = self._preprocess_image(original_image.copy())\n",
    "        \n",
    "        # PIL 이미지를 OpenCV가 요구하는 정확한 데이터 타입으로 변환\n",
    "        cropped_image_np = np.array(cropped_image)\n",
    "        cropped_image_np = cv2.cvtColor(cropped_image_np, cv2.COLOR_RGB2BGR)\n",
    "        if cropped_image_np.dtype != np.uint8:\n",
    "            cropped_image_np = cropped_image_np.astype(np.uint8)\n",
    "\n",
    "        # EasyPororoOcr 실행 및 결과 파싱\n",
    "        ocr_reader.run_ocr(cropped_image_np, debug=False)\n",
    "        ocr_results = ocr_reader.get_ocr_result()\n",
    "\n",
    "        if not ocr_results:\n",
    "            print(\"이미지에서 텍스트를 찾을 수 없습니다.\")\n",
    "            return [], original_image\n",
    "\n",
    "        # EasyPororoOcr의 출력 형식에 맞게 단어와 박스 리스트를 생성\n",
    "        raw_words_initial = [res[1] for res in ocr_results]\n",
    "        raw_boxes_initial = []\n",
    "        for res in ocr_results:\n",
    "            box = res[0]\n",
    "            x_coords = [p[0] for p in box]\n",
    "            y_coords = [p[1] for p in box]\n",
    "            # y_offset을 더해 원본 이미지 좌표로 변환\n",
    "            raw_boxes_initial.append([min(x_coords), min(y_coords) + y_offset, max(x_coords), max(y_coords) + y_offset])\n",
    "\n",
    "        words, raw_boxes = self._split_boxes_aggressively(raw_words_initial, raw_boxes_initial)\n",
    "\n",
    "        width, height = original_image.size\n",
    "        boxes = [[int(1000 * b[0] / width), int(1000 * b[1] / height), int(1000 * b[2] / width), int(1000 * b[3] / height)] for b in raw_boxes]\n",
    "\n",
    "        encoding = self.processor(\n",
    "            original_image, words, boxes=boxes, return_tensors=\"pt\",\n",
    "            padding=\"max_length\", truncation=True,\n",
    "        ).to(DEVICE)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**encoding)\n",
    "        \n",
    "        probabilities = F.softmax(outputs.logits, dim=-1)\n",
    "        predictions = torch.argmax(probabilities, dim=-1)\n",
    "        max_probs = torch.max(probabilities, dim=-1).values\n",
    "        \n",
    "        results = self._postprocess(encoding, predictions.squeeze().tolist(), max_probs.squeeze().tolist(), words, raw_boxes)\n",
    "        \n",
    "        return results, original_image\n",
    "\n",
    "    def _postprocess(self, encoding, predictions, probabilities, words, raw_boxes):\n",
    "        \"\"\"\n",
    "        예측 결과를 병합하고, 텍스트 내용과 숫자 패턴을 함께 고려하여 라벨을 재분류하는 후처리 함수.\n",
    "        (규칙 우선순위 및 정규식 강화)\n",
    "        \"\"\"\n",
    "        word_ids = encoding.word_ids(0)\n",
    "        \n",
    "        # 1. 신뢰도 기반 초기 필터링\n",
    "        initial_preds = []\n",
    "        previous_word_idx = None\n",
    "        for idx, (pred_id, prob) in enumerate(zip(predictions, probabilities)):\n",
    "            word_idx = word_ids[idx]\n",
    "            if word_idx is None or word_idx == previous_word_idx:\n",
    "                continue\n",
    "            \n",
    "            label = id2label[pred_id]\n",
    "            if label != \"O\" and prob >= self.confidence_threshold:\n",
    "                initial_preds.append({\n",
    "                    \"text\": words[word_idx], \"label\": label, \"box\": raw_boxes[word_idx],\n",
    "                    \"confidence\": prob, \"word_idx\": word_idx\n",
    "                })\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        if not initial_preds:\n",
    "            return []\n",
    "\n",
    "        # 2. 연속된 같은 라벨 병합\n",
    "        merged_preds = []\n",
    "        if initial_preds:\n",
    "            current_pred = initial_preds[0]\n",
    "            for i in range(1, len(initial_preds)):\n",
    "                next_pred = initial_preds[i]\n",
    "                if next_pred['label'] == current_pred['label'] and next_pred['word_idx'] == current_pred['word_idx'] + 1:\n",
    "                    current_pred['text'] += \" \" + next_pred['text']\n",
    "                    current_pred['box'][2] = next_pred['box'][2]\n",
    "                    current_pred['box'][3] = max(current_pred['box'][3], next_pred['box'][3])\n",
    "                    current_pred['confidence'] = max(current_pred['confidence'], next_pred['confidence'])\n",
    "                    current_pred['word_idx'] = next_pred['word_idx']\n",
    "                else:\n",
    "                    merged_preds.append(current_pred)\n",
    "                    current_pred = next_pred\n",
    "            merged_preds.append(current_pred)\n",
    "\n",
    "        # 3. ★★★ 키워드와 정규식을 함께 고려한 최종 재분류 ★★★\n",
    "        final_preds = []\n",
    "        for pred in merged_preds:\n",
    "            text = pred['text']\n",
    "            has_digits = any(char.isdigit() for char in text)\n",
    "\n",
    "            if has_digits:\n",
    "                # 금액 패턴(숫자, 쉼표, '원'으로 끝남)과 일치하는지 확인\n",
    "                is_amount_pattern = re.search(r'[\\d,]+원?$', text.strip())\n",
    "                \n",
    "                # 더 구체적인 '입금/출금'을 먼저 확인\n",
    "                if '입금' in text or '+' in text or (pred['label'] == 'AMOUNT_IN' and is_amount_pattern):\n",
    "                    pred['label'] = 'AMOUNT_IN'\n",
    "                elif '출금' in text or '-' in text or (pred['label'] == 'AMOUNT_OUT' and is_amount_pattern):\n",
    "                    pred['label'] = 'AMOUNT_OUT'\n",
    "                # 그 다음 '잔액'을 확인\n",
    "                elif '잔액' in text:\n",
    "                    pred['label'] = 'BALANCE'\n",
    "            \n",
    "            pred['confidence'] = f\"{pred['confidence']:.2f}\"\n",
    "            final_preds.append(pred)\n",
    "            \n",
    "        return final_preds\n",
    "\n",
    "print(\"DocumentPredictor 클래스가 'EasyPororoOcr' 엔진과 함께 업데이트되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f64b043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "draw_predictions 함수가 신뢰도 표시 기능과 새로운 색상 구성으로 업데이트되었습니다.\n"
     ]
    }
   ],
   "source": [
    "def draw_predictions(image, predictions, font_path=None):\n",
    "    \"\"\"예측 결과를 원본 이미지 위에 시각화합니다. (신뢰도 표시 및 색상 개선)\"\"\"\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    \n",
    "    try:\n",
    "        font = ImageFont.truetype(font_path or \"malgun.ttf\", size=15)\n",
    "    except IOError:\n",
    "        print(\"경고: 'malgun.ttf' 폰트를 찾을 수 없습니다. 기본 폰트를 사용합니다.\")\n",
    "        font = ImageFont.load_default()\n",
    "\n",
    "    # ★★★ 시인성 좋은 색상으로 변경 ★★★\n",
    "    label_colors = {\n",
    "        \"DATE_HEADER\": \"#ff7f0e\", # 주황\n",
    "        \"DATE\": \"#1f77b4\",       # 파랑\n",
    "        \"TIME\": \"#d62728\",       # 빨강\n",
    "        \"MERCHANT\": \"#2ca02c\",   # 초록\n",
    "        \"MEMO\": \"#9467bd\",       # 보라\n",
    "        \"AMOUNT_IN\": \"#8c564b\",  # 갈색\n",
    "        \"AMOUNT_OUT\": \"#e377c2\", # 핑크\n",
    "        \"BALANCE\": \"#7f7f7f\",    # 회색\n",
    "    }\n",
    "\n",
    "    for pred in predictions:\n",
    "        box = pred['box']\n",
    "        label = pred['label']\n",
    "        color = label_colors.get(label, \"#bcbd22\") # 기본값: 올리브색\n",
    "        \n",
    "        draw.rectangle(box, outline=color, width=3)\n",
    "        \n",
    "        # ★★★ 라벨 텍스트에 신뢰도 점수 추가 ★★★\n",
    "        label_text = f\"{label} ({pred['confidence']})\"\n",
    "        \n",
    "        text_bbox = draw.textbbox((box[0], box[1]), label_text, font=font)\n",
    "        text_width = text_bbox[2] - text_bbox[0]\n",
    "        text_height = text_bbox[3] - text_bbox[1]\n",
    "        \n",
    "        label_bg_box = [box[0], box[1] - text_height - 6, box[0] + text_width + 8, box[1]]\n",
    "        draw.rectangle(label_bg_box, fill=color)\n",
    "        \n",
    "        draw.text((box[0] + 4, box[1] - text_height - 4), label_text, fill=\"white\", font=font)\n",
    "        \n",
    "    return image\n",
    "\n",
    "print(\"draw_predictions 함수가 신뢰도 표시 기능과 새로운 색상 구성으로 업데이트되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90ebb33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델과 프로세서를 로딩합니다...\n",
      "OCR 엔진(EasyPororoOcr)을 초기화합니다...\n",
      "설정된 신뢰도 임계값: 0.85\n",
      "\n",
      "'KakaoTalk_20250624_075429567.png'에서 텍스트를 추출합니다...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'EasyPororoOcr' object has no attribute 'detector'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m image_path \u001b[38;5;129;01min\u001b[39;00m test_image_files:\n\u001b[0;32m     26\u001b[0m         \u001b[38;5;66;03m# 예측 수행\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m         predictions, image \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m         \u001b[38;5;66;03m# 결과 시각화\u001b[39;00m\n\u001b[0;32m     30\u001b[0m         result_image \u001b[38;5;241m=\u001b[39m draw_predictions(image\u001b[38;5;241m.\u001b[39mcopy(), predictions, font_path\u001b[38;5;241m=\u001b[39mFONT_PATH)\n",
      "Cell \u001b[1;32mIn[2], line 71\u001b[0m, in \u001b[0;36mDocumentPredictor.predict\u001b[1;34m(self, image_path)\u001b[0m\n\u001b[0;32m     68\u001b[0m     cropped_image_np \u001b[38;5;241m=\u001b[39m cropped_image_np\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# EasyPororoOcr 실행 및 결과 파싱\u001b[39;00m\n\u001b[1;32m---> 71\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mocr_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_ocr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcropped_image_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m ocr_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mocr_reader\u001b[38;5;241m.\u001b[39mget_ocr_result()\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ocr_results:\n",
      "File \u001b[1;32mc:\\code\\pororo_easyocr_main\\main.py:135\u001b[0m, in \u001b[0;36mEasyPororoOcr.run_ocr\u001b[1;34m(self, img_path, debug, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg \u001b[38;5;241m=\u001b[39m img\n\u001b[0;32m    133\u001b[0m \u001b[38;5;66;03m# ★★★ 변경점: run_ocr이 호출될 때마다 매번 새로 영역을 탐지하도록 변경 ★★★\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m# 이전에는 이 코드가 __init__에 있어 첫 이미지의 결과만 계속 사용했습니다.\u001b[39;00m\n\u001b[1;32m--> 135\u001b[0m ocr_results_raw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetector\u001b[49m\u001b[38;5;241m.\u001b[39mreadtext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg, detail\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    137\u001b[0m \u001b[38;5;66;03m# 라이브러리의 복잡한 crop/filter 로직을 모두 제거하고,\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m# EasyOCR의 결과를 Pororo OCR 형식에 맞게 단순 변환합니다.\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mocr_result \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'EasyPororoOcr' object has no attribute 'detector'"
     ]
    }
   ],
   "source": [
    "# --- 1. 설정 ---\n",
    "# 테스트할 이미지가 있는 폴더\n",
    "TEST_IMAGE_DIR = '../bank_statement_test'\n",
    "TEST_IMAGE_DIR2 = '../bank_statement'\n",
    "# 사용할 폰트 경로 (None으로 두면 시스템 기본 폰트 또는 'malgun.ttf' 시도)\n",
    "FONT_PATH = None \n",
    "\n",
    "# --- 2. 예측기 초기화 ---\n",
    "try:\n",
    "    predictor = DocumentPredictor(model_path=OUTPUT_DIR)\n",
    "except Exception as e:\n",
    "    print(f\"예측기 초기화 실패: {e}\")\n",
    "    # Stop execution if predictor fails\n",
    "    raise\n",
    "\n",
    "# --- 3. 이미지 예측 및 결과 출력 ---\n",
    "test_image_files = glob.glob(os.path.join(TEST_IMAGE_DIR, '*.png')) + \\\n",
    "                   glob.glob(os.path.join(TEST_IMAGE_DIR, '*.jpg')) + \\\n",
    "                    glob.glob(os.path.join(TEST_IMAGE_DIR2, '*.png')) + \\\n",
    "                    glob.glob(os.path.join(TEST_IMAGE_DIR2, '*.jpg'))\n",
    "\n",
    "if not test_image_files:\n",
    "    print(f\"오류: '{TEST_IMAGE_DIR}' 폴더에서 테스트 이미지를 찾을 수 없습니다.\")\n",
    "else:\n",
    "    for image_path in test_image_files:\n",
    "        # 예측 수행\n",
    "        predictions, image = predictor.predict(image_path)\n",
    "        \n",
    "        # 결과 시각화\n",
    "        result_image = draw_predictions(image.copy(), predictions, font_path=FONT_PATH)\n",
    "        \n",
    "        # 결과 출력 (이미지 및 텍스트)\n",
    "        print(f\"\\n--- [{os.path.basename(image_path)}] 정보 추출 결과 ---\")\n",
    "        display(result_image) # Jupyter Notebook 환경에서 이미지 바로 표시\n",
    "        \n",
    "        print(\"\\n[텍스트 요약]\")\n",
    "        if predictions:\n",
    "            # 보기 좋게 라벨별로 묶어서 출력\n",
    "            summary = {}\n",
    "            for p in predictions:\n",
    "                label = p['label']\n",
    "                if label not in summary:\n",
    "                    summary[label] = []\n",
    "                summary[label].append(p['text'])\n",
    "            \n",
    "            for label, texts in summary.items():\n",
    "                print(f\"- {label}: {', '.join(texts)}\")\n",
    "        else:\n",
    "            print(\"추출된 정보가 없습니다.\")\n",
    "        print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
