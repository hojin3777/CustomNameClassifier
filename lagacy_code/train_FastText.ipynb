{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be800bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import fasttext\n",
    "import os\n",
    "from konlpy.tag import Mecab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8028dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['상가업소번호', '지역', '상호명_Regulated', '업종소분류_Regulated', '클래스'], dtype='object')\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. \n",
      "\u001b[1;31m셀의 코드를 검토하여 가능한 오류 원인을 식별하세요. \n",
      "\u001b[1;31m자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'>여기</a>를 클릭하세요. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "# Mecab 토크나이저 초기화\n",
    "tokenizer = Mecab(dicpath='C:/mecab/mecab-ko-dic')\n",
    "# 데이터 준비\n",
    "def prepare_fasttext_data(data_df, output_file, tokenizer):\n",
    "    \"\"\"\n",
    "    FastText 형식으로 데이터를 준비합니다.\n",
    "    FastText는 \"__label__<class>\" 형식으로 데이터를 요구합니다.\n",
    "    Mecab 토크나이저를 사용하여 텍스트를 토크나이징합니다.\n",
    "    \"\"\"\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        for _, row in data_df.iterrows():\n",
    "            label = f\"__label__{row['class']}\"\n",
    "            # Mecab으로 토크나이징 후 공백으로 연결\n",
    "            tokens = tokenizer.morphs(str(row['store']))\n",
    "            tokenized_text = \" \".join(tokens)\n",
    "            f.write(f\"{label} {tokenized_text}\\n\")\n",
    "\n",
    "# 데이터 로드\n",
    "data_path = './processed_data/region_all_processed_data.csv'\n",
    "data_df = pd.read_csv(data_path)\n",
    "\n",
    "# 컬럼 이름 확인 및 변경\n",
    "print(data_df.columns)  # 컬럼 이름 확인\n",
    "data_df.rename(columns={'상호명_Regulated': 'store', '클래스': 'class'}, inplace=True)  # 컬럼 이름 변경\n",
    "\n",
    "# 데이터 분할\n",
    "train_df = data_df.sample(frac=0.8, random_state=42)  # 80% 훈련 데이터\n",
    "test_df = data_df.drop(train_df.index)  # 나머지 20% 테스트 데이터\n",
    "\n",
    "# FastText 형식으로 데이터 준비\n",
    "train_file = './processed_data/fasttext_train_tokenized.txt'\n",
    "test_file = './processed_data/fasttext_test_tokenized.txt'\n",
    "prepare_fasttext_data(train_df, train_file, tokenizer)\n",
    "prepare_fasttext_data(test_df, test_file, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90fdb8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습\n",
    "model_path = './saved_model/fasttext/fasttext_model4.bin'\n",
    "if not os.path.exists(model_path):\n",
    "    model = fasttext.train_supervised(\n",
    "        input=train_file,\n",
    "        epoch=50,\n",
    "        lr=0.5,\n",
    "        wordNgrams=3,\n",
    "        bucket=2000000,\n",
    "        dim=200,\n",
    "        loss='softmax'\n",
    "    )\n",
    "    model.save_model(model_path)\n",
    "else:\n",
    "    model = fasttext.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f406085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "상호명: 스타벅스R리저브강남대로점 -> 업종: 214 (확률: 86.17%)\n",
      "테스트 데이터 정확도: 61.40%\n"
     ]
    }
   ],
   "source": [
    "# 추론 함수\n",
    "def predict_store_class(model, tokenizer, store_name):\n",
    "    \"\"\"\n",
    "    FastText 모델을 사용하여 상호명으로 업종을 예측합니다.\n",
    "    입력된 상호명은 학습 데이터와 동일하게 토크나이징되어야 합니다.\n",
    "    \"\"\"\n",
    "    # Mecab으로 토크나이징 후 공백으로 연결\n",
    "    tokens = tokenizer.morphs(str(store_name))\n",
    "    tokenized_text = \" \".join(tokens)\n",
    "    \n",
    "    prediction = model.predict(tokenized_text)\n",
    "    label = prediction[0][0].replace(\"__label__\", \"\")\n",
    "    confidence = prediction[1][0] * 100\n",
    "    return label, confidence\n",
    "\n",
    "# 테스트\n",
    "test_store = \"스타벅스R리저브강남대로점\"\n",
    "# 추론 시에도 토크나이저를 사용해야 합니다.\n",
    "predicted_class, confidence = predict_store_class(model, tokenizer, test_store)\n",
    "print(f\"상호명: {test_store} -> 업종: {predicted_class} (확률: {confidence:.2f}%)\")\n",
    "\n",
    "# 테스트 데이터 평가\n",
    "correct = 0\n",
    "total = len(test_df)\n",
    "for _, row in test_df.iterrows():\n",
    "    # 추론 함수에 토크나이저를 전달합니다.\n",
    "    predicted_class, _ = predict_store_class(model, tokenizer, row['store'])\n",
    "    if predicted_class == str(row['class']):\n",
    "        correct += 1\n",
    "accuracy = correct / total * 100\n",
    "print(f\"테스트 데이터 정확도: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4216318e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터 정확도: 64.04%\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습 (자동 튜닝)\n",
    "model_path = './saved_model/fasttext/fasttext_model_autotune.bin'\n",
    "if not os.path.exists(model_path):\n",
    "    # autotuneValidationFile에 검증 데이터를 지정하고, autotuneDuration으로 튜닝 시간(초)을 설정합니다.\n",
    "    model = fasttext.train_supervised(\n",
    "        input=train_file,\n",
    "        autotuneValidationFile=test_file,\n",
    "        autotuneDuration=3600  # 30분 동안 자동 튜닝\n",
    "    )\n",
    "    model.save_model(model_path)\n",
    "else:\n",
    "    model = fasttext.load_model(model_path)\n",
    "\n",
    "# 모델 평가\n",
    "# model.test() 함수를 사용하면 (샘플 수, 정밀도, 재현율)을 반환합니다.\n",
    "result = model.test(test_file)\n",
    "print(f\"테스트 데이터 정확도: {result[1] * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c83bbc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "자동 튜닝으로 찾은 최적 하이퍼파라미터:\n",
      "- 학습률 (lr): 0.05\n",
      "- 임베딩 차원 (dim): 135\n",
      "- 에포크 (epoch): 4\n",
      "- 단어 n-gram (wordNgrams): 4\n",
      "- 손실 함수 (loss): loss_name.softmax\n",
      "- 버킷 크기 (bucket): 3408660\n"
     ]
    }
   ],
   "source": [
    "# 자동 튜닝으로 저장된 모델 로드\n",
    "model_path = './saved_model/fasttext/fasttext_model_autotune.bin'\n",
    "model = fasttext.load_model(model_path)\n",
    "\n",
    "# 모델 학습에 사용된 하이퍼파라미터 조회\n",
    "args = model.f.getArgs()\n",
    "\n",
    "# 결과 출력\n",
    "print(\"자동 튜닝으로 찾은 최적 하이퍼파라미터:\")\n",
    "print(f\"- 학습률 (lr): {args.lr}\")\n",
    "print(f\"- 임베딩 차원 (dim): {args.dim}\")\n",
    "print(f\"- 에포크 (epoch): {args.epoch}\")\n",
    "print(f\"- 단어 n-gram (wordNgrams): {args.wordNgrams}\")\n",
    "print(f\"- 손실 함수 (loss): {args.loss}\")\n",
    "print(f\"- 버킷 크기 (bucket): {args.bucket}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f93a600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사전 학습된 모델을 사용하여 파인튜닝을 시작합니다...\n",
      "파인튜닝 완료. 모델이 ./saved_model/fasttext/fasttext_model_finetuned.bin에 저장되었습니다.\n",
      "\n",
      "파인튜닝된 모델 성능 평가:\n",
      "테스트 데이터 정확도: 63.49%\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "import os\n",
    "\n",
    "# 사전 학습된 모델 파일 경로\n",
    "pretrained_vectors_path = './saved_model/fasttext/cc.ko.300.vec' \n",
    "# 파인튜닝된 모델을 저장할 경로\n",
    "finetuned_model_path = './saved_model/fasttext/fasttext_model_finetuned.bin'\n",
    "\n",
    "# 이전에 준비한 학습 데이터 파일\n",
    "train_file = './processed_data/fasttext_train_tokenized.txt'\n",
    "test_file = './processed_data/fasttext_test_tokenized.txt'\n",
    "\n",
    "if not os.path.exists(finetuned_model_path):\n",
    "    print(\"사전 학습된 모델을 사용하여 파인튜닝을 시작합니다...\")\n",
    "    # train_supervised에 pretrainedVectors 인자를 추가합니다.\n",
    "    # 이전에 찾은 최적의 하이퍼파라미터를 사용합니다.\n",
    "    model_finetuned = fasttext.train_supervised(\n",
    "        input=train_file,\n",
    "        pretrainedVectors=pretrained_vectors_path,\n",
    "        epoch=4,\n",
    "        lr=0.05,\n",
    "        wordNgrams=4,\n",
    "        dim=300,  # 중요: pretrained vector의 차원(300)과 일치시켜야 합니다.\n",
    "        loss='softmax'\n",
    "    )\n",
    "    model_finetuned.save_model(finetuned_model_path)\n",
    "    print(f\"파인튜닝 완료. 모델이 {finetuned_model_path}에 저장되었습니다.\")\n",
    "else:\n",
    "    print(f\"이미 파인튜닝된 모델({finetuned_model_path})을 로드합니다.\")\n",
    "    model_finetuned = fasttext.load_model(finetuned_model_path)\n",
    "\n",
    "# 파인튜닝된 모델 성능 평가\n",
    "print(\"\\n파인튜닝된 모델 성능 평가:\")\n",
    "result_finetuned = model_finetuned.test(test_file)\n",
    "print(f\"테스트 데이터 정확도: {result_finetuned[1] * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cbc7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파인튜닝을 위한 자동 튜닝을 시작합니다...\n"
     ]
    }
   ],
   "source": [
    "# 사전 학습된 모델 파일 경로\n",
    "pretrained_vectors_path = './saved_model/fasttext/cc.ko.300.vec'\n",
    "# 파인튜닝 + 자동튜닝된 모델을 저장할 경로\n",
    "autotuned_finetuned_model_path = './saved_model/fasttext/fasttext_model_autotune_finetuned.bin'\n",
    "\n",
    "# 데이터 파일 경로\n",
    "train_file = './processed_data/fasttext_train_tokenized.txt'\n",
    "test_file = './processed_data/fasttext_test_tokenized.txt'\n",
    "\n",
    "if not os.path.exists(autotuned_finetuned_model_path):\n",
    "    print(\"파인튜닝을 위한 자동 튜닝을 시작합니다...\")\n",
    "    # autotune을 실행하되, pretrainedVectors 인자를 추가합니다.\n",
    "    model_autotune_finetuned = fasttext.train_supervised(\n",
    "        input=train_file,\n",
    "        pretrainedVectors=pretrained_vectors_path,\n",
    "        autotuneValidationFile=test_file,\n",
    "        autotuneDuration=3600  # 30분 동안 자동 튜닝\n",
    "    )\n",
    "    model_autotune_finetuned.save_model(autotuned_finetuned_model_path)\n",
    "    print(f\"파인튜닝 자동 튜닝 완료. 모델이 {autotuned_finetuned_model_path}에 저장되었습니다.\")\n",
    "else:\n",
    "    print(f\"이미 자동 튜닝된 파인튜닝 모델({autotuned_finetuned_model_path})을 로드합니다.\")\n",
    "    model_autotune_finetuned = fasttext.load_model(autotuned_finetuned_model_path)\n",
    "\n",
    "# 최종 모델 성능 평가\n",
    "print(\"\\n자동 튜닝된 파인튜닝 모델 성능 평가:\")\n",
    "result = model_autotune_finetuned.test(test_file)\n",
    "print(f\"테스트 데이터 정확도: {result[1] * 100:.2f}%\")\n",
    "\n",
    "# 최적 하이퍼파라미터 확인\n",
    "print(\"\\n파인튜닝을 위해 찾은 최적 하이퍼파라미터:\")\n",
    "args = model_autotune_finetuned.f.getArgs()\n",
    "print(f\"- 학습률 (lr): {args.lr}\")\n",
    "print(f\"- 에포크 (epoch): {args.epoch}\")\n",
    "print(f\"- 단어 n-gram (wordNgrams): {args.wordNgrams}\")\n",
    "print(f\"- 손실 함수 (loss): {args.loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a0eaca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
